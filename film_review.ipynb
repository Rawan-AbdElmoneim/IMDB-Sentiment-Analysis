{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zxJgtOqMs6LY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import string\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou9b4xfWtdl_",
        "outputId": "43b06df3-4c3c-42e1-c51b-5c057be7513f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('/content/IMDB Dataset.csv')\n",
        "\n",
        "# Print the first 5 rows\n",
        "print(df.head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WDxu683tdoU",
        "outputId": "a7a5b98e-1b93-40d7-959f-f8bd2f756378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive reviews: 25000\n",
            "Number of negative reviews: 25000\n"
          ]
        }
      ],
      "source": [
        "# Count the number of positive and negative reviews\n",
        "sentiment_counts = df['sentiment'].value_counts()\n",
        "\n",
        "# Print the counts\n",
        "print(\"Number of positive reviews:\", sentiment_counts['positive'])\n",
        "print(\"Number of negative reviews:\", sentiment_counts['negative'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BGWvsD09tdqs"
      },
      "outputs": [],
      "source": [
        "X = df['review'].astype(str)\n",
        "y = df['sentiment'].map({'positive': 1, 'negative': 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnA0lX_ItdtC",
        "outputId": "2c417cb6-773a-48df-c0b9-f81c0fc9e34d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of X: 50000\n",
            "Length of y: 50000\n"
          ]
        }
      ],
      "source": [
        "print(\"Length of X:\", len(X))\n",
        "print(\"Length of y:\", len(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9Ni7aiptdvL",
        "outputId": "c70d9a43-3ac1-4e1d-a313-3c82c3ba837d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        One of the other reviewers has mentioned that ...\n",
              "1        A wonderful little production. <br /><br />The...\n",
              "2        I thought this was a wonderful way to spend ti...\n",
              "3        Basically there's a family where a little boy ...\n",
              "4        Petter Mattei's \"Love in the Time of Money\" is...\n",
              "                               ...                        \n",
              "49995    I thought this movie did a down right good job...\n",
              "49996    Bad plot, bad dialogue, bad acting, idiotic di...\n",
              "49997    I am a Catholic taught in parochial elementary...\n",
              "49998    I'm going to have to disagree with the previou...\n",
              "49999    No one expects the Star Trek movies to be high...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQnCCK0gtdyl",
        "outputId": "a435e345-ad15-4c4c-b532-ae3f1185d4c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1\n",
              "1        1\n",
              "2        1\n",
              "3        0\n",
              "4        1\n",
              "        ..\n",
              "49995    1\n",
              "49996    0\n",
              "49997    0\n",
              "49998    0\n",
              "49999    0\n",
              "Name: sentiment, Length: 50000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABrW1f8QtnQs",
        "outputId": "ae68c3b0-b1da-4bf5-8573-e86119ad5c86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "# Load NLTK WordNet for lemmatization\n",
        "nltk.download('wordnet')\n",
        "# Create instances for lemmatization and stemming\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T91DaNS0tnTH"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove non-word characters and special characters\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Lowercasing\n",
        "    text = text.lower()\n",
        "    # Tokenize the data\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stop words\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    # Apply lemmatization and stemming\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "    # Join tokens back into a string\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "    return preprocessed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vbaA2m09tr5X"
      },
      "outputs": [],
      "source": [
        "Xp = X.apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSeJ1Pdqtr8A",
        "outputId": "32352ff6-b35f-4888-a8ce-a95d9530fa18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        one review mention watch oz episod youll hook ...\n",
              "1        wonder littl product film techniqu unassum old...\n",
              "2        thought wonder way spend time hot summer weeke...\n",
              "3        basic there famili littl boy jake think there ...\n",
              "4        petter mattei love time money visual stun film...\n",
              "                               ...                        \n",
              "49995    thought movi right good job wasnt creativ orig...\n",
              "49996    bad plot bad dialogu bad act idiot direct anno...\n",
              "49997    cathol taught parochi elementari school nun ta...\n",
              "49998    im go disagre previou comment side maltin one ...\n",
              "49999    one expect star trek movi high art fan expect ...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "Xp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e7sML8Qtr-l",
        "outputId": "1b52a710-a3cb-49ff-a0fd-0f8fb99039bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1\n",
              "1        1\n",
              "2        1\n",
              "3        0\n",
              "4        1\n",
              "        ..\n",
              "49995    1\n",
              "49996    0\n",
              "49997    0\n",
              "49998    0\n",
              "49999    0\n",
              "Name: sentiment, Length: 50000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFhupCLbtsCE",
        "outputId": "1e57323e-e61b-4f5c-dad7-f60d54d28228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of X: 50000\n",
            "Length of y: 50000\n"
          ]
        }
      ],
      "source": [
        "print(\"Length of X:\", len(X))\n",
        "print(\"Length of y:\", len(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pt65_K6utnWo"
      },
      "outputs": [],
      "source": [
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(Xp)\n",
        "Xp_sequences = tokenizer.texts_to_sequences(Xp)\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "max_sequence_length = max([len(seq) for seq in Xp_sequences])\n",
        "Xp_pad = pad_sequences(Xp_sequences, maxlen=max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Empkae_ht3P1",
        "outputId": "94c3885a-5c98-48cd-9122-f0de88ad5cb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,   448,  3350,   387],\n",
              "       [    0,     0,     0, ...,   278,    20,   153],\n",
              "       [    0,     0,     0, ...,    16,    10,   128],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,  3267, 16177,  1063],\n",
              "       [    0,     0,     0, ...,  1799,  1437,   321],\n",
              "       [    0,     0,     0, ...,   911,   611,     1]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "Xp_pad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "O9mBgST4t3Sl"
      },
      "outputs": [],
      "source": [
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByIr50xht6YF",
        "outputId": "f733bc83-baab-4887-aac7-91871159df72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "y_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sdh5WHftt6ao"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xp_pad, y_encoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY0dCk5bt3WH"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0))\n",
        "model.add(Dense(64, activation='relu'))  # Adding a dense layer\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "joGLkXrtt_Ts"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlHPPNy6t_WQ",
        "outputId": "c52cca23-c27c-452e-a713-59d02c2571d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 116s 178ms/step - loss: 0.3552 - accuracy: 0.8434 - val_loss: 0.2769 - val_accuracy: 0.8850\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 72s 115ms/step - loss: 0.1725 - accuracy: 0.9362 - val_loss: 0.2908 - val_accuracy: 0.8853\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 59s 95ms/step - loss: 0.0975 - accuracy: 0.9653 - val_loss: 0.4069 - val_accuracy: 0.8700\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 50s 80ms/step - loss: 0.0592 - accuracy: 0.9792 - val_loss: 0.4773 - val_accuracy: 0.8657\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 50s 80ms/step - loss: 0.0417 - accuracy: 0.9857 - val_loss: 0.5822 - val_accuracy: 0.8695\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 46s 73ms/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.5431 - val_accuracy: 0.8612\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.5088 - val_accuracy: 0.8605\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.6220 - val_accuracy: 0.8694\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.7289 - val_accuracy: 0.8586\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.7344 - val_accuracy: 0.8599\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7eefc17a7550>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8jz_7itt_ZG",
        "outputId": "b961b556-c60e-4808-e91f-e514ba4ba34c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 6s 18ms/step - loss: 0.7344 - accuracy: 0.8599\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0jbCTU8t_cS",
        "outputId": "bf895a8e-5fe1-4362-f2f9-5fa1c1b66afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "Text: The film lacks depth and fails to engage the audience. A forgettable experience --> Sentiment: B=Negative\n",
            "Text: Poorly executed storyline and lackluster acting make it hard to stay interested. Not worth the ticket price --> Sentiment: B=Negative\n"
          ]
        }
      ],
      "source": [
        "# New text data for prediction\n",
        "new_texts = [\"The film lacks depth and fails to engage the audience. A forgettable experience\", \"Poorly executed storyline and lackluster acting make it hard to stay interested. Not worth the ticket price\"]\n",
        "\n",
        "# Tokenize and pad the new text data\n",
        "new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
        "new_padded_sequences = pad_sequences(new_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(new_padded_sequences)\n",
        "\n",
        "# Convert predictions to sentiment labels\n",
        "sentiment_labels = ['Postive' if pred > 0.5 else 'B=Negative' for pred in predictions]\n",
        "\n",
        "# Print predictions\n",
        "for text, label in zip(new_texts, sentiment_labels):\n",
        "    print(f'Text: {text} --> Sentiment: {label}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "V7gTG5Qu6WAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4224158-f5c9-4068-cbb7-381b5856e5c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 101ms/step\n",
            "Text: Disappointing. Predictable plot and dull performances make it a waste of time --> Sentiment: Negative\n",
            "Text: This film is a masterpiece, captivating from beginning to end. A must-watch! --> Sentiment: Positive\n"
          ]
        }
      ],
      "source": [
        "# New text data for prediction\n",
        "new_texts = [\"Disappointing. Predictable plot and dull performances make it a waste of time\", \"This film is a masterpiece, captivating from beginning to end. A must-watch!\"]\n",
        "\n",
        "# Tokenize and pad the new text data\n",
        "new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
        "new_padded_sequences = pad_sequences(new_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(new_padded_sequences)\n",
        "\n",
        "# Convert predictions to sentiment labels\n",
        "sentiment_labels = ['Positive' if pred > 0.5 else 'Negative' for pred in predictions]\n",
        "\n",
        "# Print predictions\n",
        "for text, label in zip(new_texts, sentiment_labels):\n",
        "    print(f'Text: {text} --> Sentiment: {label}')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}